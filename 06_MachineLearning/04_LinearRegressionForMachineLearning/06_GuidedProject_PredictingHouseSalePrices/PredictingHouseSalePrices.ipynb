{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Data Set\n",
    "*  Import pandas, matplotlib, and numpy into the environment. Import the classes you need from scikit-learn as well.\n",
    "*  Read __AmesHousing.txt__ into a pandas data frame.\n",
    "*  For the following functions, we recommend creating them in the first few cells in the notebook. This way, you can add cells to the end of the notebook to do experiments and update the functions in these cells.\n",
    "  *  Create a function named __transform_features()__ that, for now, just returns the __train__ data frame.\n",
    "  *  Create a function named __select_features()__ that, for now, just returns the __Gr Liv Area__ and __SalePrice__ columns from the __train__ data frame.\n",
    "  *  Create a function named __train_and_test()__ that, for now:\n",
    "    *  Selects the first __1460__ rows from from __data__ and assign to __train__.\n",
    "    *  Selects the remaining rows from __data__ and assign to __test__.\n",
    "    *  Trains a model using all numerical columns except the __SalePrice__ column (the target column) from the data frame returned from __select_features()__\n",
    "    *  Tests the model on the test set using and returns the RMSE value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('AmesHousing.txt', delimiter='\\t')\n",
    "train = data.iloc[:1460].copy()\n",
    "test = data.iloc[1460:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_features(train):\n",
    "    df = train.copy()\n",
    "    return df\n",
    "\n",
    "def select_features():\n",
    "    return ['Gr Liv Area'], 'SalePrice'\n",
    "\n",
    "def train_and_test(train, test, train_features, target):\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[train_features],train[target])\n",
    "    predict = lr.predict(test[train_features])\n",
    "    mse = mean_squared_error(test[target],predict)\n",
    "    RMSE = np.sqrt(mse)\n",
    "    \n",
    "    return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.251612639091"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features, target = select_features()\n",
    "RMSE = train_and_test(train, test, train_features, target)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "*  As we mentioned earlier, we recommend adding some cells to explore and experiment with different features (before rewriting these functions).\n",
    "*  The __transform_features()__ function shouldn't modify the __train__ data frame and instead return a new one entirely. This way, we can keep using __train__ in the experimentation cells.\n",
    "*  Which columns contain less than 5% missing values?\n",
    "  *  For numerical columns that meet this criteria, let's fill in the missing values using the most popular value for that column.\n",
    "*  What new features can we create, that better capture the information in some of the features?\n",
    "  *  An example of this would be the __years_until_remod__ feature we created in the last mission.\n",
    "*  Which columns need to be dropped for other reasons?\n",
    "  *  Which columns aren't useful for machine learning?\n",
    "  *  Which columns leak data about the final sale?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 39 columns):\n",
      "Order              1460 non-null int64\n",
      "PID                1460 non-null int64\n",
      "MS SubClass        1460 non-null int64\n",
      "Lot Frontage       1211 non-null float64\n",
      "Lot Area           1460 non-null int64\n",
      "Overall Qual       1460 non-null int64\n",
      "Overall Cond       1460 non-null int64\n",
      "Year Built         1460 non-null int64\n",
      "Year Remod/Add     1460 non-null int64\n",
      "Mas Vnr Area       1449 non-null float64\n",
      "BsmtFin SF 1       1459 non-null float64\n",
      "BsmtFin SF 2       1459 non-null float64\n",
      "Bsmt Unf SF        1459 non-null float64\n",
      "Total Bsmt SF      1459 non-null float64\n",
      "1st Flr SF         1460 non-null int64\n",
      "2nd Flr SF         1460 non-null int64\n",
      "Low Qual Fin SF    1460 non-null int64\n",
      "Gr Liv Area        1460 non-null int64\n",
      "Bsmt Full Bath     1459 non-null float64\n",
      "Bsmt Half Bath     1459 non-null float64\n",
      "Full Bath          1460 non-null int64\n",
      "Half Bath          1460 non-null int64\n",
      "Bedroom AbvGr      1460 non-null int64\n",
      "Kitchen AbvGr      1460 non-null int64\n",
      "TotRms AbvGrd      1460 non-null int64\n",
      "Fireplaces         1460 non-null int64\n",
      "Garage Yr Blt      1385 non-null float64\n",
      "Garage Cars        1460 non-null float64\n",
      "Garage Area        1460 non-null float64\n",
      "Wood Deck SF       1460 non-null int64\n",
      "Open Porch SF      1460 non-null int64\n",
      "Enclosed Porch     1460 non-null int64\n",
      "3Ssn Porch         1460 non-null int64\n",
      "Screen Porch       1460 non-null int64\n",
      "Pool Area          1460 non-null int64\n",
      "Misc Val           1460 non-null int64\n",
      "Mo Sold            1460 non-null int64\n",
      "Yr Sold            1460 non-null int64\n",
      "SalePrice          1460 non-null int64\n",
      "dtypes: float64(11), int64(28)\n",
      "memory usage: 444.9 KB\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the train DF and show all the numerical columns\n",
    "train_copy = transform_features(train)\n",
    "numerical_train = train_copy.select_dtypes(include=['int64', 'float64'])\n",
    "numerical_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Order', 'PID', 'MS SubClass', 'Lot Area', 'Overall Qual',\n",
      "       'Overall Cond', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area',\n",
      "       'BsmtFin SF 1', 'BsmtFin SF 2', 'Bsmt Unf SF', 'Total Bsmt SF',\n",
      "       '1st Flr SF', '2nd Flr SF', 'Low Qual Fin SF', 'Gr Liv Area',\n",
      "       'Bsmt Full Bath', 'Bsmt Half Bath', 'Full Bath', 'Half Bath',\n",
      "       'Bedroom AbvGr', 'Kitchen AbvGr', 'TotRms AbvGrd', 'Fireplaces',\n",
      "       'Garage Cars', 'Garage Area', 'Wood Deck SF', 'Open Porch SF',\n",
      "       'Enclosed Porch', '3Ssn Porch', 'Screen Porch', 'Pool Area', 'Misc Val',\n",
      "       'Mo Sold', 'Yr Sold', 'SalePrice'],\n",
      "      dtype='object')\n",
      "\n",
      "Verify there are no missing values in the DataFrame\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Order              0\n",
       "PID                0\n",
       "MS SubClass        0\n",
       "Lot Area           0\n",
       "Overall Qual       0\n",
       "Overall Cond       0\n",
       "Year Built         0\n",
       "Year Remod/Add     0\n",
       "Mas Vnr Area       0\n",
       "BsmtFin SF 1       0\n",
       "BsmtFin SF 2       0\n",
       "Bsmt Unf SF        0\n",
       "Total Bsmt SF      0\n",
       "1st Flr SF         0\n",
       "2nd Flr SF         0\n",
       "Low Qual Fin SF    0\n",
       "Gr Liv Area        0\n",
       "Bsmt Full Bath     0\n",
       "Bsmt Half Bath     0\n",
       "Full Bath          0\n",
       "Half Bath          0\n",
       "Bedroom AbvGr      0\n",
       "Kitchen AbvGr      0\n",
       "TotRms AbvGrd      0\n",
       "Fireplaces         0\n",
       "Garage Cars        0\n",
       "Garage Area        0\n",
       "Wood Deck SF       0\n",
       "Open Porch SF      0\n",
       "Enclosed Porch     0\n",
       "3Ssn Porch         0\n",
       "Screen Porch       0\n",
       "Pool Area          0\n",
       "Misc Val           0\n",
       "Mo Sold            0\n",
       "Yr Sold            0\n",
       "SalePrice          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the numerial columns that have less than 5% missing values\n",
    "isnull_percentage = numerical_train.isnull().sum()/numerical_train.shape[0]\n",
    "cols_Numerical_LessThanFivePercentNulls = isnull_percentage[isnull_percentage < 0.05].index\n",
    "print(cols_Numerical_LessThanFivePercentNulls)\n",
    "numerical_train = train_copy[cols_Numerical_LessThanFivePercentNulls].copy()\n",
    "\n",
    "# From these columns fill the missing values with the most common value (mode).\n",
    "# Note, if there are multiple modes, the column will be filled with the mean of the modes\n",
    "numerical_train = numerical_train.fillna(numerical_train.mode().iloc[0])\n",
    "print('\\nVerify there are no missing values in the DataFrame')\n",
    "numerical_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([         'Lot Area',      'Overall Qual',      'Overall Cond',\n",
       "            'Mas Vnr Area',      'BsmtFin SF 1',      'BsmtFin SF 2',\n",
       "             'Bsmt Unf SF',     'Total Bsmt SF',        '1st Flr SF',\n",
       "              '2nd Flr SF',   'Low Qual Fin SF',       'Gr Liv Area',\n",
       "          'Bsmt Full Bath',    'Bsmt Half Bath',         'Full Bath',\n",
       "               'Half Bath',     'Bedroom AbvGr',     'Kitchen AbvGr',\n",
       "           'TotRms AbvGrd',        'Fireplaces',       'Garage Cars',\n",
       "             'Garage Area',      'Wood Deck SF',     'Open Porch SF',\n",
       "          'Enclosed Porch',        '3Ssn Porch',      'Screen Porch',\n",
       "               'Pool Area',          'Misc Val',         'SalePrice',\n",
       "                        20,                  30,                  40,\n",
       "                        45,                  50,                  60,\n",
       "                        70,                  75,                  80,\n",
       "                        85,                  90,                 120,\n",
       "                       160,                 180,                 190,\n",
       "       'years_until_remod'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The following columns can be dropped as they are not useful for machine learning\n",
    "# I will comment that I am thinking that Mo Sold & Yr Sold might be valuable for converting the\n",
    "# sale price into an inflationary adjusted value.  For now I'm going to leave that alone.\n",
    "# cols_drop = ['Order', 'PID', 'Mo Sold', 'Yr Sold']\n",
    "numerical_train = numerical_train.drop(['Order', 'PID', 'Mo Sold', 'Yr Sold'], axis=1)\n",
    "\n",
    "# The MS SubClass Column requires categorization/dummies\n",
    "numerical_train['MS SubClass'] = numerical_train['MS SubClass'].astype('category')\n",
    "col_dummies = pd.get_dummies(numerical_train['MS SubClass'])\n",
    "numerical_train = pd.concat([numerical_train, col_dummies], axis=1)\n",
    "numerical_train = numerical_train.drop(['MS SubClass'], axis=1)\n",
    "\n",
    "# Converts nominal/categorical numerical data which contains values that\n",
    "# don't directly correlate to the target value, into numerical values that do correlate to the target\n",
    "# In this case uses the 'Year Remod/Add' & 'Year Built' columns to calculate the years after the house\n",
    "# was built until it was remodeled\n",
    "numerical_train['years_until_remod'] = numerical_train['Year Remod/Add'] - numerical_train['Year Built']\n",
    "numerical_train = numerical_train.drop(['Year Remod/Add', 'Year Built'], axis=1)\n",
    "\n",
    "# Print the columns\n",
    "numerical_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "*  Generate a correlation heatmap matrix of the numerical features in the training data set.\n",
    "  *  Which features correlate strongly with our target column, __SalePrice__?\n",
    "  *  Calculate the correlation coefficients for the columns that seem to correlate well with __SalePrice__. Because we have a pipeline in place, it's easy to try different features and see which features result in a better cross validation score.\n",
    "*  Which columns in the data frame should be converted to the categorical data type? All of the columns marked as __nominal__ from the [documentation](DataDocumentation.txt) are candidates for being converted to categorical. Here are some other things you should think about:\n",
    "  *  If a categorical column has hundreds of unique values (or categories), should you keep it? When you dummy code this column, hundreds of columns will need to be added back to the data frame.\n",
    "  *  Which categorical columns have a few unique values but more than 95% of the values in the column belong to a specific category? This would be similar to a low variance numerical feature (no variability in the data for the model to capture).\n",
    "*  Which columns are currently numerical but need to be encoded as categorical instead (because the numbers don't have any semantic meaning)?\n",
    "*  What are some ways we can explore which categorical columns \"correlate\" well with __SalePrice__?\n",
    "  *  Read this post for some [potential strategies](https://machinelearningmastery.com/feature-selection-machine-learning-python/).\n",
    "*  Update the logic for the __select_features()__ function. This function should take in the new, modified train and test data frames that were returned from __transform_features()__."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 Train & Test\n",
    "*  The optional __k__ parameter should accept integer values, with a default value of __0__.\n",
    "*  When __k__ equals __0__, perform holdout validation (what we already implemented):\n",
    "  *  Select the first __1460__ rows and assign to __train__.\n",
    "  *  Select the remaining rows and assign to __test__.\n",
    "  *  Train on train and test on __test__.\n",
    "  *  Compute the RMSE and return.\n",
    "*  When __k__ equals __1__, perform simple cross validation:\n",
    "  *  Shuffle the ordering of the rows in the data frame.\n",
    "  *  Select the first __1460__ rows and assign to __fold_one__.\n",
    "  *  Select the remaining rows and assign to __fold_two__.\n",
    "  *  Train on __fold_one__ and test on __fold_two__.\n",
    "  *  Train on __fold_two__ and test on __fold_one__.\n",
    "  *  Compute the average RMSE and return.\n",
    "*  When __k__ is greater than __0__, implement k-fold cross validation using __k__ folds:\n",
    "  *  Perform k-fold cross validation using __k__ folds.\n",
    "  *  Calculate the average RMSE value and return this value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
