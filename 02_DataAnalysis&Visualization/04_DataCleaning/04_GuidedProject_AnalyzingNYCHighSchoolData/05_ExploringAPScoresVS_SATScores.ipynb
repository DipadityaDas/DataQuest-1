{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mpl_toolkits.basemap'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3b6d56db37b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmpl_toolkits\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasemap\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBasemap\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m data_files = [\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mpl_toolkits.basemap'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Read in the data\n",
    "import pandas\n",
    "import numpy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "data_files = [\n",
    "    \"ap_2010.csv\",\n",
    "    \"class_size.csv\",\n",
    "    \"demographics.csv\",\n",
    "    \"graduation.csv\",\n",
    "    \"hs_directory.csv\",\n",
    "    \"sat_results.csv\"\n",
    "]\n",
    "\n",
    "data = {}\n",
    "\n",
    "for f in data_files:\n",
    "    d = pandas.read_csv(\"schools/{0}\".format(f))\n",
    "    data[f.replace(\".csv\", \"\")] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the surveys\n",
    "all_survey = pandas.read_csv(\"schools/survey_all.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "d75_survey = pandas.read_csv(\"schools/survey_d75.txt\", delimiter=\"\\t\", encoding='windows-1252')\n",
    "survey = pandas.concat([all_survey, d75_survey], axis=0)\n",
    "\n",
    "survey[\"DBN\"] = survey[\"dbn\"]\n",
    "\n",
    "survey_fields = [\n",
    "    \"DBN\", \n",
    "    \"rr_s\", \n",
    "    \"rr_t\", \n",
    "    \"rr_p\", \n",
    "    \"N_s\", \n",
    "    \"N_t\", \n",
    "    \"N_p\", \n",
    "    \"saf_p_11\", \n",
    "    \"com_p_11\", \n",
    "    \"eng_p_11\", \n",
    "    \"aca_p_11\", \n",
    "    \"saf_t_11\", \n",
    "    \"com_t_11\", \n",
    "    \"eng_t_10\", \n",
    "    \"aca_t_11\", \n",
    "    \"saf_s_11\", \n",
    "    \"com_s_11\", \n",
    "    \"eng_s_11\", \n",
    "    \"aca_s_11\", \n",
    "    \"saf_tot_11\", \n",
    "    \"com_tot_11\", \n",
    "    \"eng_tot_11\", \n",
    "    \"aca_tot_11\",\n",
    "]\n",
    "survey = survey.loc[:,survey_fields]\n",
    "data[\"survey\"] = survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add DBN columns\n",
    "data[\"hs_directory\"][\"DBN\"] = data[\"hs_directory\"][\"dbn\"]\n",
    "\n",
    "def pad_csd(num):\n",
    "    string_representation = str(num)\n",
    "    if len(string_representation) > 1:\n",
    "        return string_representation\n",
    "    else:\n",
    "        return \"0\" + string_representation\n",
    "    \n",
    "data[\"class_size\"][\"padded_csd\"] = data[\"class_size\"][\"CSD\"].apply(pad_csd)\n",
    "data[\"class_size\"][\"DBN\"] = data[\"class_size\"][\"padded_csd\"] + data[\"class_size\"][\"SCHOOL CODE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert columns to numeric\n",
    "cols = ['SAT Math Avg. Score', 'SAT Critical Reading Avg. Score', 'SAT Writing Avg. Score']\n",
    "for c in cols:\n",
    "    data[\"sat_results\"][c] = pandas.to_numeric(data[\"sat_results\"][c], errors=\"coerce\")\n",
    "\n",
    "data['sat_results']['sat_score'] = data['sat_results'][cols[0]] + data['sat_results'][cols[1]] + data['sat_results'][cols[2]]\n",
    "\n",
    "def find_lat(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lat = coords[0].split(\",\")[0].replace(\"(\", \"\")\n",
    "    return lat\n",
    "\n",
    "def find_lon(loc):\n",
    "    coords = re.findall(\"\\(.+, .+\\)\", loc)\n",
    "    lon = coords[0].split(\",\")[1].replace(\")\", \"\").strip()\n",
    "    return lon\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lat)\n",
    "data[\"hs_directory\"][\"lon\"] = data[\"hs_directory\"][\"Location 1\"].apply(find_lon)\n",
    "\n",
    "data[\"hs_directory\"][\"lat\"] = pandas.to_numeric(data[\"hs_directory\"][\"lat\"], errors=\"coerce\")\n",
    "data[\"hs_directory\"][\"lon\"] = pandas.to_numeric(data[\"hs_directory\"][\"lon\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Condense datasets\n",
    "class_size = data[\"class_size\"]\n",
    "class_size = class_size[class_size[\"GRADE \"] == \"09-12\"]\n",
    "class_size = class_size[class_size[\"PROGRAM TYPE\"] == \"GEN ED\"]\n",
    "\n",
    "class_size = class_size.groupby(\"DBN\").agg(numpy.mean)\n",
    "class_size.reset_index(inplace=True)\n",
    "data[\"class_size\"] = class_size\n",
    "\n",
    "data[\"demographics\"] = data[\"demographics\"][data[\"demographics\"][\"schoolyear\"] == 20112012]\n",
    "\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Cohort\"] == \"2006\"]\n",
    "data[\"graduation\"] = data[\"graduation\"][data[\"graduation\"][\"Demographic\"] == \"Total Cohort\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert AP scores to numeric\n",
    "cols = ['AP Test Takers ', 'Total Exams Taken', 'Number of Exams with scores 3 4 or 5']\n",
    "\n",
    "for col in cols:\n",
    "    data[\"ap_2010\"][col] = pandas.to_numeric(data[\"ap_2010\"][col], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "combined = data[\"sat_results\"]\n",
    "\n",
    "combined = combined.merge(data[\"ap_2010\"], on=\"DBN\", how=\"left\")\n",
    "combined = combined.merge(data[\"graduation\"], on=\"DBN\", how=\"left\")\n",
    "\n",
    "to_merge = [\"class_size\", \"demographics\", \"survey\", \"hs_directory\"]\n",
    "\n",
    "for m in to_merge:\n",
    "    combined = combined.merge(data[m], on=\"DBN\", how=\"inner\")\n",
    "\n",
    "combined = combined.fillna(combined.mean())\n",
    "combined = combined.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add a school district column for mapping\n",
    "\n",
    "def get_first_two_chars(dbn):\n",
    "    return dbn[0:2]\n",
    "\n",
    "combined[\"school_dist\"] = combined[\"DBN\"].apply(get_first_two_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations\n",
    "correlations = combined.corr()\n",
    "correlations = correlations[\"sat_score\"]\n",
    "print(correlations[survey_fields].sort_values(ascending=False, na_position='last'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting survey correlations\n",
    "correlations[survey_fields].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=blue>The following Survey Fields had the best coorelation to SAT scores.</font>\n",
    "\n",
    "\n",
    "| Field | Abv | r value |\n",
    "| :----- | :----- | :----- |\n",
    "|Number of student respondents| N_s | 0.423463 |\n",
    "|Number of parent respondents| N_p | 0.421530 |\n",
    "|Academic expectations score based on student responses | aca_s_11 | 0.339435 |\n",
    "|Safety and Respect score based on student responses | saf_s_11 | 0.337639 |\n",
    "|Safety and Respect total score | saf_tot_11 | 0.318753 |\n",
    "| Safety and Respect score based on teacher responses| saf_t_11 | 0.313810 |\n",
    "<br>\n",
    "<font color=red>Safety and respect seem to coorelate well with SAT scores.</font>\n",
    "<br>\n",
    "<font color=red>3 of the top 6 correlating survey fields are related to safety and respect</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a scatter plot of the saf_s_11 column vs. the sat_score in combined.\n",
    "\n",
    "title_text = 'SAT Score vs. Safety and Respect score\\nbased on student responses\\nr value = %f' % correlations['saf_s_11']\n",
    "combined.plot.scatter(x='saf_s_11', y='sat_score', title=title_text)\n",
    "\n",
    "saf_s_11_data = combined['saf_s_11']\n",
    "sat_score_data = combined['sat_score']\n",
    "\n",
    "plt.show()\n",
    "\n",
    "mean_saf_s_11_greater_than_7_5 = sat_score_data[saf_s_11_data >= 7.5].mean()\n",
    "mean_saf_s_11_greater_than_7_5 = round(mean_saf_s_11_greater_than_7_5,1)\n",
    "\n",
    "count_saf_s_11_greater_than_7_5 = sat_score_data[combined['saf_s_11']>= 7.5].count()\n",
    "count_saf_s_11_greater_than_7_5_SATabove1400 = sat_score_data[(combined['saf_s_11']>= 7.5) & (combined['sat_score'] >= 1400)].count() \n",
    "percent_saf_s_11_greater_than_7_5_SATabove1400 = count_saf_s_11_greater_than_7_5_SATabove1400 / count_saf_s_11_greater_than_7_5\n",
    "percent_saf_s_11_greater_than_7_5_SATabove1400 = round(percent_saf_s_11_greater_than_7_5_SATabove1400*100,1)\n",
    "\n",
    "print('**Safety score > 7.5**\\n')\n",
    "print('Average SAT score when the student\\nrespondent safety score > 7.5: ', mean_saf_s_11_greater_than_7_5)\n",
    "print('\\nPercentage of students with an SAT score > 1400\\nand the safety score is > 7.5: %f' % percent_saf_s_11_greater_than_7_5_SATabove1400)\n",
    "\n",
    "mean_saf_s_11_less_than_7_5 = sat_score_data[saf_s_11_data < 7.5].mean()\n",
    "mean_saf_s_11_less_than_7_5 = round(mean_saf_s_11_less_than_7_5,1)\n",
    "\n",
    "count_saf_s_11_less_than_7_5 = sat_score_data[combined['saf_s_11']< 7.5].count()\n",
    "count_saf_s_11_less_than_7_5_SATabove1400 = sat_score_data[(combined['saf_s_11']< 7.5) & (combined['sat_score'] >= 1400)].count() \n",
    "percent_saf_s_11_less_than_7_5_SATabove1400 = count_saf_s_11_less_than_7_5_SATabove1400 / count_saf_s_11_less_than_7_5\n",
    "percent_saf_s_11_less_than_7_5_SATabove1400 = round(percent_saf_s_11_less_than_7_5_SATabove1400*100,1)\n",
    "\n",
    "print('\\n\\n**Safety score < 7.5**\\n')\n",
    "print('Average SAT score when the student\\nrespondent safety score < 7.5:', mean_saf_s_11_less_than_7_5)\n",
    "print('\\nPercentage of students with an SAT score > 1400\\nand the safety score is < 7.5: %f' % percent_saf_s_11_less_than_7_5_SATabove1400)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=blue>Conclusion regarding safety score coorelation to SAT score.</font>\n",
    "### <font color=red>The following lists correlations between safety and SAT scores</font>\n",
    "<br>\n",
    "-  <font color=black>The average SAT score is 185 points higher when the student based safety score is greater than 7.5</font>\n",
    "-  <font color=black>39.1% of the SAT scores are 1400+ when the safety score is above 7.5</font>\n",
    "-  <font color=black>7.5% of the SAT scores are 1400+ when the safety score is below 7.5</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map out safety scores.\n",
    "# Compute the average safety score for each district.\n",
    "    \n",
    "districts = combined.groupby('school_dist').agg(numpy.mean)\n",
    "districts.reset_index(inplace=True)\n",
    "\n",
    "# Make a map that shows safety scores by district.\n",
    "m = Basemap(\n",
    "    projection='merc', \n",
    "    llcrnrlat=40.496044, \n",
    "    urcrnrlat=40.915256, \n",
    "    llcrnrlon=-74.255735, \n",
    "    urcrnrlon=-73.700272,\n",
    "    resolution='i'\n",
    ")\n",
    "\n",
    "m.drawmapboundary(fill_color='#85A6D9')\n",
    "m.drawcoastlines(color='#6D5F47', linewidth=.4)\n",
    "m.drawrivers(color='#6D5F47', linewidth=.4)\n",
    "# Temporary bug: if you run the following line of code in the Jupyter Guided Project interface on Dataquest, you'll get an error. \n",
    "# We're working on a fix, thanks for your patience! This should work fine locally on your own computer though.\n",
    "m.fillcontinents(color='white',lake_color='#85A6D9')\n",
    "\n",
    "longitudes = districts[\"lon\"].tolist()\n",
    "latitudes = districts[\"lat\"].tolist()\n",
    "m.scatter(longitudes, latitudes, s=50, zorder=2, latlon=True, c=districts[\"saf_s_11\"], cmap=\"summer\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=red>It looks like Upper Manhattan and parts of Queens and the Bronx tend to have lower safety scores, whereas Brooklyn has high safety scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate racial differences in SAT scores.\n",
    "    # Make a bar plot of the correlations between the columns above and sat_score.\n",
    "    # Write up a Markdown cell containing your findings. Are there any unexpected correlations?\n",
    "\n",
    "demographic_cols = ['white_per', 'asian_per', 'black_per', 'hispanic_per']\n",
    "combined.corr()[\"sat_score\"][demographic_cols].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- <font color=blue>A higher percentage of white and asian students coorelate with higher SAT scores.  This is represented by a relatively large positive r values.</font>\n",
    "- <font color=blue>A lower percentage of black and hispanic students coorelate with higher SAT scores.  This is represented by a relatively large negative r values.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore schools with low SAT scores and high values for hispanic_per.\n",
    "    # Make a scatter plot of hispanic_per vs. sat_score.\n",
    "    # What does the scatter plot show? Record any interesting observsations in a Markdown cell.\n",
    "combined.plot.scatter(x='hispanic_per', y='sat_score', title='hispanic_per vs. sat_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=black>This plots shows that schools that have greater than ~ 25% hispanic have a drastically reduced SAT scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research any schools with a hispanic_per greater than 95%.\n",
    "    # Find the school names in the data.\n",
    "    # Use Wikipedia and Google to research the schools by name.\n",
    "    # Is there anything interesting about these particular schools? Record your findings in a Markdown cell.\n",
    "\n",
    "school_names_95perPlus_hispanic = combined['SCHOOL NAME'][combined['hispanic_per'] > 95.0]\n",
    "school_names_95perPlus_hispanic_SAT_mean = combined['sat_score'][combined['hispanic_per'] > 95.0].mean()\n",
    "print(school_names_95perPlus_hispanic)\n",
    "print('\\nThe mean SAT score is', school_names_95perPlus_hispanic_SAT_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=black>The schools listed above appear to primarily be geared towards recent immigrants to the US. These schools have a lot of students who are learning English, which would explain the lower SAT scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research any schools with a hispanic_per less than 10% and an average SAT score greater than 1800.\n",
    "    # Find the school names in the data.\n",
    "    # Use Wikipedia and Google to research the schools by name.\n",
    "    # Is there anything interesting about these particular schools? Record your findings in a Markdown cell.\n",
    "    \n",
    "school_names_10perMinus_hispanic = combined['SCHOOL NAME'][(combined['hispanic_per'] < 10.0) & (combined['sat_score'] > 1800)]\n",
    "school_names_10perMinus_hispanic_SAT_mean = combined['sat_score'][(combined['hispanic_per'] < 10.0) & (combined['sat_score'] > 1800)].mean()\n",
    "print(school_names_10perMinus_hispanic)\n",
    "print('\\nThe mean SAT score is', school_names_10perMinus_hispanic_SAT_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=black>Many of the schools above appear to be specialized science and technology schools that receive extra funding, and only admit students who pass an entrance exam. This doesn't explain the low hispanic_per, but it does explain why their students tend to do better on the SAT -- they are students from all over New York City who did well on a standardized test.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate gender differences in SAT scores.\n",
    "    # Make a bar plot of the correlations between the columns above and sat_score.\n",
    "    # Record your findings in a Markdown cell. Are there any unexpected correlations?\n",
    "    \n",
    "gender_cols = ['male_per', 'female_per']\n",
    "combined.corr()[\"sat_score\"][gender_cols].plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=black>There is a small correlation showing that schools with a greater % of girls do better on SAT scores.  Alternatively, there is a similar magnitude of coorleation showing that schools with a smaller % of boys do better on SAT scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate schools with high SAT scores and a high female_per.\n",
    "    # Make a scatter plot of female_per vs. sat_score.\n",
    "    # What does the scatter plot show? Record any interesting observations in a Markdown cell.\n",
    "    \n",
    "combined.plot.scatter(x='female_per', y='sat_score', title='female_per vs. sat_score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=black>Based on the scatterplot, there doesn't seem to be any real correlation between sat_score and female_per. However, there is a cluster of schools with a high percentage of females (60 to 80), and high SAT scores.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Research any schools with a female_per greater than 60% and an average SAT score greater than 1700.\n",
    "    # Find the school names in the data.\n",
    "    # Use Wikipedia and Google to research the schools by name.\n",
    "    # Is there anything interesting about these particular schools? Record your findings in a Markdown cell.\n",
    "    \n",
    "print(combined['SCHOOL NAME'][(combined['female_per'] > 60) & (combined['sat_score'] > 1700)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=black>These schools appears to be very selective liberal arts schools that have high academic standards.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the percentage of students in each school that took an AP exam.\n",
    "    # Divide the AP Test Takers column by the total_enrollment column.\n",
    "    # The column name AP Test Takers has a space at the end -- don't forget to add it!\n",
    "    # Assign the result to the ap_per column.\n",
    "\n",
    "combined['ap_per'] = (combined['AP Test Takers '] / combined['total_enrollment']) * 100\n",
    "\n",
    "# Investigate the relationship between AP scores and SAT scores.\n",
    "    # Make a scatter plot of ap_per vs. sat_score.\n",
    "    # What does the scatter plot show? Record any interesting observations in a Markdown cell.\n",
    "\n",
    "r_value = combined.corr()['sat_score']['ap_per']\n",
    "t = 'r value = %f\\nap_per vs. sat_score' % r_value\n",
    "combined.plot.scatter(x='ap_per', y='sat_score', title=t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color =black>There is a very weak coorelation between the percentage of students taking AP exams and SAT scores</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
